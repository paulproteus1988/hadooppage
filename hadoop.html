<!doctype html>
<html >
<head>
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!--[if lt IE 9]>
                <script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
        <![endif]-->
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Style-Type" content="text/css" />

    <link href="https://fonts.googleapis.com/css?family=Domine|Montserrat" rel="stylesheet"> 
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
    <!-- <link rel="stylesheet" type="text/css" href="template.css" /> -->
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/template.css" />

    <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />

    <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
    <!-- <script type='text/javascript' src='menu/js/jquery.cookie.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.hoverIntent.minified.js'></script> -->
    <!-- <script type='text/javascript' src='menu/js/jquery.dcjqaccordion.2.7.min.js'></script> -->
    <!-- <link href="menu/css/skins/blue.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/graphite.css" rel="stylesheet" type="text/css" /> -->
    <!-- <link href="menu/css/skins/grey.css" rel="stylesheet" type="text/css" /> -->
    <!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
    <!-- <script src="script.js"></script> -->
    <!-- <script src="jquery.sticky-kit.js "></script> -->
    <script type='text/javascript' src='https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/js/jquery.cookie.js'></script>
    <script type='text/javascript' src='https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/js/jquery.hoverIntent.minified.js'></script>
    <script type='text/javascript' src='https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/js/jquery.dcjqaccordion.2.7.min.js'></script>

    <link href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/css/skins/blue.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/css/skins/graphite.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/menu/css/skins/grey.css" rel="stylesheet" type="text/css" />
    <link href="https://cdn.jsdelivr.net/gh/ryangrose/easy-pandoc-templates@948e28e5/css/elegant_bootstrap.css" rel="stylesheet" type="text/css" />
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
    <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/script.js"></script>
  
    <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-bootstrap-adaptive-template@959c3622/jquery.sticky-kit.js"></script>
    <meta name="generator" content="pandoc" />
  <title>Hadoop Three Node Guide</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">body { font-family: Domine, Georgia, Palatino, 'Palatino Linotype', Times, 'Times New Roman', serif} h1, h2, h3, h4, h5, h6 { font-family: Montserrat, sans }</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>

    
    <div class="container mt-5">
      <div class="row">
            <div class="col-12">
		<h1> Hadoop Three Node Guide </h1>
		<p>I've included spaces for you to input your nodes' IP addresses. You can find them on the Oracle Website (<a href="https://imgur.com/Cmzb9RY">Example</a>). I am only using amd1 (master-node), arm1 (node-arm1), and arm2 (node-arm2) for the cluster. NOTE: THESE ARE JUST FOR YOUR REFERENCE, THEY DO NOT CHANGE ANY VALUES IN MY INSTRUCTIONS. WHENEVER YOU SEE MASTERPUBLIC, MASTERPRIVATE, WORKER1PRIVATE, or WORKER2PRIVATE IN THE GUIDE, YOU MUST REPLACE IT WITH THE ASSOCIATED IP ADDRESS FOR YOUR FILES. In a perfect world I'd have them automatically replaced on this page but uhh, I'm pretty bad with JavaScript.</p>
		MASTERPUBLIC <input type="text" id="textone"><br>   
                MASTERPRIVATE <input type="text" id="textone"><br>   
                WORKER1PRIVATE <input type="text" id="textone"><br>   
                WORKER2PRIVATE <input type="text" id="textone">
<h2 id="modify-hostname-and-hosts-file-on-each-node">Modify hostname and
hosts file on Each Node</h2>
<p>The master node (AMD1) and each worker node (ARM1 and ARM2) will need
to have a modified /etc/hosts file.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> sudo vim /etc/hosts</span></code></pre></div>
<pre class="text"><code>/etc/hosts

10.0.0.180      node-master
10.0.0.147      node-amd1
10.0.0.253      node-arm1
10.0.0.241      node-arm2</code></pre>
<p>You will also need to modify the /etc/hostname file for each node as
well.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> sudo vim /etc/hostname</span></code></pre></div>
<p>For the master node, /etc/hostname should be:</p>
<pre class="text"><code>/etc/hostname

node-master</code></pre>
<p>the first worker node’s /etc/hostname file should be:</p>
<pre class="text"><code>/etc/hostname

node-arm1</code></pre>
<p>and the second worker node’s /etc/hostname file should be:</p>
<pre class="text"><code>/etc/hostname

node-arm2</code></pre>
<h2 id="connecting-the-nodes-with-ssh">Connecting the nodes with
SSH</h2>
<p>In order to have the nodes connect with one another, you need to
create ssh keys for them and add the public keys to each node’s
authorized_keys file. Start with node-master:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> ssh-keygen <span class="at">-t</span> ed25519 <span class="at">-C</span> <span class="st">&quot;youremail@yourdomain.com&quot;</span></span></code></pre></div>
<p>Press enter multiple times to use the default values for each input.
Make sure you <strong>DO NOT</strong> set a password but instead leave
it blank. The output should look something like this:</p>
<pre class="text"><code>hadoop@node-master:~ $ ssh-keygen -t ed25519 -C &quot;gleb@reys.net&quot;
Generating public/private ed25519 key pair.
Enter file in which to save the key (/Users/greys/.ssh/id_ed25519):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /Users/greys/.ssh/id_ed25519.
Your public key has been saved in /Users/greys/.ssh/id_ed25519.pub.
The key fingerprint is:
SHA256:FHsTyFHNmvNpw4o7+rp+M1yqMyBF8vXSBRkZtkQ0RKY gleb@reys.net
The key&#39;s randomart image is:
+--[ED25519 256]--+
|       */Xoo     |
|  . . .===..o    |
|   + .Eo+.oo     |
|    o ..o.+.     |
|   .   .S  + .   |
|  . .     . *    |
|   . . . + o .   |
|      o O .      |
|     .*Xo=       |
+----[SHA256]-----+</code></pre>
<p>You then need to find your public key. It should be stored in
~/.ssh/id_ed25519.pub. You can show this value using the cat
command:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> cat ~/.ssh/id_ed25519.pub</span></code></pre></div>
<p>The output will be similar to the following. Make sure to copy and
paste this value to a text file you can access on your local PC.</p>
<pre class="text"><code>ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIK0wmN/Cr3JXqmLW7u+g9pTh+wyqDHpSQEIQczXkVx9q gleb@reys.net</code></pre>
<p>You will then do the same exact thing for your two worker nodes,
making sure you copy and paste their id_ed25519.pub values to the same
text file as the previous step. You will end up with a text file with
three public keys, similar to the following:</p>
<pre class="text"><code>ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIK0wmN/Cr3JXqmLW7u+g9pTh+wyqDHpSQEIQczXkVx9q gleb@reys.net
ssh-ed25519 AAAAC3NzaC123DFLJAMCLA123LJMMA/Cr3JXqmLW7DFL123+p23jjKKAQEIQczXkVx9q gleb@reys.net
ssh-ed25519 AAAAC3NzaC1lZDI1234556NDLK0wmN/Cr3JXqmLW7u+gsdafjl+adf2SQEIQczXkVx9q gleb@reys.net</code></pre>
<p>You will then need to copy the three keys from your file and paste
them into a newly created file on <strong>each node</strong>. The newly
created file is called authorized_keys and it will be located in
~/.ssh</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/.ssh/authorized_keys</span></code></pre></div>
<pre class="text"><code>/home/hadoop/.ssh/authorized_keys

ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIK0wmN/Cr3JXqmLW7u+g9pTh+wyqDHpSQEIQczXkVx9q gleb@reys.net
ssh-ed25519 AAAAC3NzaC123DFLJAMCLA123LJMMA/Cr3JXqmLW7DFL123+p23jjKKAQEIQczXkVx9q gleb@reys.net
ssh-ed25519 AAAAC3NzaC1lZDI1234556NDLK0wmN/Cr3JXqmLW7u+gsdafjl+adf2SQEIQczXkVx9q gleb@reys.net</code></pre>
<p>Make sure you also create this file on node-arm1 and node-arm2, using
the same instructions. You should now be able to ssh into the nodes from
each node. Test this before you continue:</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> ssh node-arm1</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> ssh node-arm2</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm2:~$</span> ssh node-master</span></code></pre></div>
<p>If you can ssh from each node to the other, you can now continue to
setting up hadoop.</p>
<h2 id="setting-up-hadoop">Setting up Hadoop</h2>
<h3 id="master-node">Master Node</h3>
<h4 id="downloading-and-extracting-hadoop">Downloading and Extracting
hadoop</h4>
<p>ssh into your master node, then download the binary for hadoop and
extract it using the following commands:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> tar xvf hadoop-3.3.4.tar.gz</span></code></pre></div>
<p>It’s then a good idea to rename the resulting extracted folder as
just “hadoop”:</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> mv hadoop-3.3.4 hadoop</span></code></pre></div>
<p>Now you’ll need to add the hadoop bin and sbin folder to your PATH.
The best way to do this is through modifying your .bashrc file. We can
also export HADOOP_HOME the same way.</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/.bashrc</span></code></pre></div>
<p>Add the following lines to your .bashrc file:</p>
<pre class="text"><code>/home/hadoop/.bashrc

export HADOOP_HOME=/home/hadoop/hadoop
export PATH=$PATH:/home/hadoop/hadoop/bin:/home/hadoop/hadoop/sbin</code></pre>
<p>Now source the file to apply the changes:</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> source ~/.bashrc</span></code></pre></div>
<p>You can check your PATH with the following command to make sure it
has been added and that your HADOOP_HOME is set correctly:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> echo <span class="va">$PATH</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> echo <span class="va">$HADOOP_HOME</span></span></code></pre></div>
<p>You can also verify that you added it correctly by running the hadoop
process, though at this point it will most likely give you a JAVA_HOME
error, which is fine. #+begin_src bash hadoop@node-master:~$ hadoop
#+end_srcy</p>
<h4 id="setting-java-home">Setting JAVA_HOME</h4>
<p>Find your java folder’s name by using the following command:</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> ls /usr/lib/jvm</span></code></pre></div>
<p>In my case, it listed the following folders and files (If you’re
using Java 8 it will be similar but with 8 instead of 11):</p>
<pre class="text"><code>default-java  java-1.11.0-openjdk-amd64  java-11-openjdk-amd64  openjdk-11</code></pre>
<p>You’ll then need to modify the hadoop-env.sh file. It’s located at
~/hadoop/etc/hadoop/hadoop-env.sh:</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/hadoop/etc/hadoop/hadoop-env.sh</span></code></pre></div>
<p>Within that file you will find the line “export
JAVA_HOME=${JAVA_HOME}”. Replace “{JAVA_HOME}” with the path of your
JAVA folder (NOTE: THIS IS THE PATH FOR MY SYSTEM WITH JAVA 11. MAKE
SURE YOU PUT THE CORRECT PATH FOR YOUR SYSTEM IF YOU’RE RUNNING JAVA
8):</p>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/hadoop-env.sh

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</code></pre>
<p>Test this by running the hadoop application and seeing if the
JAVA_HOME error is gone. If it is, you can continue.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> hadoop</span></code></pre></div>
<h4 id="modifying-core-site-dot-xml">Modifying core-site.xml</h4>
<p>We’re now moving on to configuring the hadoop xml files in order to
set up and connect our cluster. First we’ll modify core-site.xml. It’s
located at ~/hadoop/etc/hadoop/core-site.xml</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/hadoop/etc/hadoop/core-site.xml</span></code></pre></div>
<p>You will need to replace what’s inside the &lt;value&gt; tag with the
private IP address of your master node:</p>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/core-site.xml

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
    &lt;configuration&gt;
        &lt;property&gt;
            &lt;name&gt;fs.default.name&lt;/name&gt;
            &lt;value&gt;hdfs://MASTERPRIVATE:9000&lt;/value&gt;
        &lt;/property&gt;
    &lt;/configuration&gt;</code></pre>
<h4 id="modifying-hdfs-site-dot-xml">Modifying hdfs-site.xml</h4>
<p>We’ll now modify the file for setting up our hdfs file system. The
location is ~hadoop/etc/hadoop/hdfs-site.xml. Since we’re only using the
master-node as a master (e.g. not a worker as well), we can just add the
following to set up the master’s nameNode:</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/hadoop/etc/hadoop/hdfs-site.xml</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/hdfs-site.xml

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
            &lt;value&gt;/home/hadoop/data/nameNode&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
            &lt;name&gt;dfs.replication&lt;/name&gt;
            &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<h4 id="modifying-mapred-site-dot-xml">Modifying mapred-site.xml</h4>
<p>We’ll now modify our map reduce settings so that YARN is its default
framework. The file is located at
~/hadoop/etc/hadoop/mapred-site.xml.</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/hadoop/etc/hadoop/mapred-site.xml</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/mapred-site.xml

&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
            &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;mapreduce.map.env&lt;/name&gt;
            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;
    &lt;/property&gt;
        &lt;property&gt;
        &lt;name&gt;yarn.app.mapreduce.am.resource.mb&lt;/name&gt;
        &lt;value&gt;3072&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;
        &lt;value&gt;1536&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;
        &lt;value&gt;1536&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p>The last three properties scale up the memory usage to values that
are more appropriate for our worker nodes’ 12GB of RAM.</p>
<h4 id="modifying-yarn-site-dot-xml">Modifying yarn-site.xml</h4>
<p>We’ll now modify our yarn configuration to include the hostname and
address (private IP in this case) of our master node. It’s location is
~/hadoop/etc/hadoop/yarn-site.xml</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/hadoop/etc/hadoop/yarn-site.xml</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/yarn-site.xml

&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;
&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;yarn.acl.enable&lt;/name&gt;
            &lt;value&gt;0&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
            &lt;value&gt;MASTERPRIVATE&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
       &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
       &lt;value&gt;MASTERPRIVATE:8032&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
        &lt;value&gt;9216&lt;/value&gt;
     &lt;/property&gt;

     &lt;property&gt;
        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
        &lt;value&gt;9216&lt;/value&gt;
     &lt;/property&gt;

     &lt;property&gt;
        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
        &lt;value&gt;768&lt;/value&gt;
     &lt;/property&gt;

     &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p>The last few properties are again related to scaling memory to match
our 12GB of RAM.</p>
<h4 id="modifying-workers-file">Modifying workers file</h4>
<p>Lastly we just need to specify our worker nodes using the “workers”
file. You can just add the names defined in our /etc/hosts file. The
file to modify is located at ~/hadoop/etc/hadoop/workers:</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> vim ~/hadoop/etc/hadoop/workers</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/workers

node-arm1
node-arm2</code></pre>
<h4 id="create-namenode-directory">Create namenode directory</h4>
<p>You need to create the directory you specified in hdfs-site.xml. You
can create it using the following command:</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> mkdir <span class="at">-p</span> ~/data/nameNode</span></code></pre></div>
<p>Your master-node should now be fully configured, we’ll move on to the
worker nodes.</p>
<h3 id="worker-nodes">Worker Nodes</h3>
<p>The steps to configure your worker nodes will be very similar but
different in a few key ways. The most important of which is that we’ll
be using a different hadoop binary that’s been compiled for the ARM64
architecture. I haven’t tried to use the regular binary on the arm
nodes, so it’s possible it just works too, but there’s no real reason to
use that over the arm64 binary I provide IMO. Start by ssh’ing into your
first worker node (node-arm1). You can do this directly from
node-master.</p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> ssh node-arm1</span></code></pre></div>
<p>Now that you’re in node-arm1, your prompt should start with
hadoop@node-arm1. If it does, you can continue.</p>
<h4 id="downloading-and-extracting-hadoop">Downloading and Extracting
hadoop</h4>
<p>ssh into your master node, then download the binary for hadoop and
extract it using the following commands:</p>
<div class="sourceCode" id="cb38"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> wget https://transfer.sh/get/o6xO6i/hadoop-3.3.4.tar.gz</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> tar xvf hadoop-3.3.4.tar.gz</span></code></pre></div>
<p>It’s then a good idea to rename the resulting extracted folder as
just “hadoop”:</p>
<div class="sourceCode" id="cb39"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> mv hadoop-3.3.4 hadoop</span></code></pre></div>
<p>Now you’ll need to add the hadoop bin and sbin folder to your PATH.
The best way to do this is through modifying your .bashrc file. We can
also export HADOOP_HOME the same way.</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> vim ~/.bashrc</span></code></pre></div>
<p>Add the following lines to your .bashrc file:</p>
<pre class="text"><code>/home/hadoop/.bashrc

export HADOOP_HOME=/home/hadoop/hadoop
export PATH=$PATH:/home/hadoop/hadoop/bin:/home/hadoop/hadoop/sbin</code></pre>
<p>Now source the file to apply the changes:</p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> source ~/.bashrc</span></code></pre></div>
<p>You can check your PATH with the following command to make sure it
has been added and check that your HADOOP_HOME is set correctly:</p>
<div class="sourceCode" id="cb43"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> echo <span class="va">$PATH</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> echo <span class="va">$HADOOP_HOME</span></span></code></pre></div>
<p>You can also verify that you added it correctly by running the hadoop
process, though at this point it will most likely give you a JAVA_HOME
error, which is fine.</p>
<div class="sourceCode" id="cb44"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> hadoop</span></code></pre></div>
<!--list-separator-->
<ul>
<li><p>Setting JAVA_HOME</p>
<p>Find your java folder’s name by using the following command:</p>
<div class="sourceCode" id="cb45"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> ls /usr/lib/jvm</span></code></pre></div>
<p>In my case, it listed the following folders and files (If you’re
using Java 8 it will be similar but with 8 instead of 11):</p>
<pre class="text"><code>default-java  java-1.11.0-openjdk-arm64  java-11-openjdk-arm64  openjdk-11</code></pre>
<p>You’ll then need to modify the hadoop-env.sh file. It’s located at
~/hadoop/etc/hadoop/hadoop-env.sh:</p>
<div class="sourceCode" id="cb47"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> vim ~/hadoop/etc/hadoop/hadoop-env.sh</span></code></pre></div>
<p>Within that file you will find the line “export
JAVA_HOME=${JAVA_HOME}”. Replace “{JAVA_HOME}” with the path of your
JAVA folder (NOTE: THIS IS THE PATH FOR MY SYSTEM WITH JAVA 11. MAKE
SURE YOU PUT THE CORRECT PATH FOR YOUR SYSTEM IF YOU’RE RUNNING JAVA
8):</p>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/hadoop-env.sh

export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-arm64</code></pre>
<p>Test this by running the hadoop application and seeing if the
JAVA_HOME error is gone. If it is, you can continue.</p>
<div class="sourceCode" id="cb49"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> hadoop</span></code></pre></div></li>
</ul>
<h4 id="modifying-core-site-dot-xml">Modifying core-site.xml</h4>
<p>We’re now moving on to configuring the hadoop xml files in order to
set up and connect our cluster. First we’ll modify core-site.xml. It’s
located at ~/hadoop/etc/hadoop/core-site.xml</p>
<div class="sourceCode" id="cb50"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> vim ~/hadoop/etc/hadoop/core-site.xml</span></code></pre></div>
<p>You will need to replace what’s inside the &lt;value&gt; tag with the
private IP address of your master node:</p>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/core-site.xml

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
    &lt;configuration&gt;
        &lt;property&gt;
            &lt;name&gt;fs.default.name&lt;/name&gt;
            &lt;value&gt;hdfs://MASTERPRIVATE:9000&lt;/value&gt;
        &lt;/property&gt;
    &lt;/configuration&gt;</code></pre>
<h4 id="modifying-hdfs-site-dot-xml">Modifying hdfs-site.xml</h4>
<p>We’ll now modify the file for setting up our hdfs file system. The
location is ~hadoop/etc/hadoop/hdfs-site.xml. Since we’re</p>
<div class="sourceCode" id="cb52"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> vim ~/hadoop/etc/hadoop/hdfs-site.xml</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/hdfs-site.xml

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
            &lt;value&gt;/home/hadoop/data/dataNode&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
            &lt;name&gt;dfs.replication&lt;/name&gt;
            &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<h4 id="modifying-mapred-site-dot-xml">Modifying mapred-site.xml</h4>
<p><strong>NOTE: This is unchanged from the file we created on the
master-node (It needs to be the same on all nodes.)</strong> We’ll now
modify our map reduce settings so that YARN is its default framework.
The file is located at ~/hadoop/etc/hadoop/mapred-site.xml.</p>
<div class="sourceCode" id="cb54"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> vim ~/hadoop/etc/hadoop/mapred-site.xml</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/mapred-site.xml

&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
            &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;mapreduce.map.env&lt;/name&gt;
            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;
    &lt;/property&gt;
        &lt;property&gt;
        &lt;name&gt;yarn.app.mapreduce.am.resource.mb&lt;/name&gt;
        &lt;value&gt;3072&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;
        &lt;value&gt;1536&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;
        &lt;value&gt;1536&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<p>The last three properties scale up the memory usage to values that
are more appropriate for our worker nodes’ 12GB of RAM.</p>
<h4 id="modifying-yarn-site-dot-xml">Modifying yarn-site.xml</h4>
<p><strong>NOTE: This is unchanged from the file we created on the
master-node (It needs to be the same on all nodes.)</strong> We’ll now
modify our yarn configuration to include the hostname and address
(private IP in this case) of our master node. It’s location is
~/hadoop/etc/hadoop/yarn-site.xml</p>
<div class="sourceCode" id="cb56"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> vim ~/hadoop/etc/hadoop/yarn-site.xml</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/yarn-site.xml

&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;
&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;yarn.acl.enable&lt;/name&gt;
            &lt;value&gt;0&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
            &lt;value&gt;MASTERPRIVATE&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
       &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
       &lt;value&gt;MASTERPRIVATE:8032&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
        &lt;value&gt;9216&lt;/value&gt;
     &lt;/property&gt;

     &lt;property&gt;
        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
        &lt;value&gt;9216&lt;/value&gt;
     &lt;/property&gt;

     &lt;property&gt;
        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
        &lt;value&gt;768&lt;/value&gt;
     &lt;/property&gt;

     &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
<h4 id="modifying-workers-file">Modifying workers file</h4>
<p><strong>NOTE: This is unchanged from the file we created on the
master-node (It needs to be the same on all nodes.)</strong> Lastly we
just need to specify our worker nodes using the “workers” file. You can
just add the names defined in our /etc/hosts file. The file to modify is
located at ~/hadoop/etc/hadoop/workers:</p>
<div class="sourceCode" id="cb58"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> vim ~/hadoop/etc/hadoop/workers</span></code></pre></div>
<pre class="text"><code>/home/hadoop/hadoop/etc/hadoop/workers

node-arm1
node-arm2</code></pre>
<h4 id="create-datanode-directory">Create datanode directory</h4>
<p>You need to create the directory you specified in hdfs-site.xml. You
can create it using the following command:</p>
<div class="sourceCode" id="cb60"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> mkdir <span class="at">-p</span> ~/data/dataNode</span></code></pre></div>
<p>node-arm1 is now fully configured. Repeat these exact same
instructions for node-arm2 and you will have two fully configured worker
nodes.</p>
<h2 id="opening-all-ports-on-oracle-vm">Opening all ports on Oracle
VM</h2>
<p>Login to your Oracle Cloud account and navigate to the virtual cloud
network security list page.</p>
<p><a href="https://imgur.com/36KKIvz"
class="uri">https://imgur.com/36KKIvz</a></p>
<p><a href="https://imgur.com/0ko1UcZ"
class="uri">https://imgur.com/0ko1UcZ</a></p>
<p><a href="https://imgur.com/29lO2ZE"
class="uri">https://imgur.com/29lO2ZE</a></p>
<p>Click “Add Ingress Rules”</p>
<p><a href="https://imgur.com/Qpd3XEz"
class="uri">https://imgur.com/Qpd3XEz</a></p>
<p>Click on IP Protocol and change it to All Protocols, then click Add
Ingress Rules</p>
<p><a href="https://imgur.com/AfeWJAo"
class="uri">https://imgur.com/AfeWJAo</a></p>
<p><a href="https://imgur.com/cknBDtR"
class="uri">https://imgur.com/cknBDtR</a></p>
<p>You should now see a new rule allowing traffic from all ports.</p>
<p><a href="https://imgur.com/0FDJg0e"
class="uri">https://imgur.com/0FDJg0e</a></p>
<h2 id="starting-hadoop">Starting Hadoop</h2>
<p>ssh into your master node. All commands will be run on your master
node and you won’t need to access your worker nodes directly (except for
checking/troubleshooting.)</p>
<h3 id="format-hdfs">Format HDFS</h3>
<p>You’ll need to start by formatting your hdfs file system by using the
following command <strong>(NOTE, YOU ONLY NEED TO DO THIS ONCE, NOT
EVERY TIME YOU START HADOOP)</strong>:</p>
<div class="sourceCode" id="cb61"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> hdfs namenode <span class="at">-format</span></span></code></pre></div>
<h3 id="start-hdfs">Start HDFS</h3>
<p>You can start the hdfs file system with the following command:</p>
<div class="sourceCode" id="cb62"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> start-dfs.sh</span></code></pre></div>
<p>This should start NameNode and SecondaryNameNode on node-master, and
DataNode on node-arm1 and node-arm2. If you see a different name for
SecondaryNameNode (i.e. not “node-master”), check your /etc/hosts file
to make sure Ubuntu didn’t add a new entry with a 127.0.1.1 address. Use
the jps command to check that these nodes were started correctly on each
node. For the master node:</p>
<div class="sourceCode" id="cb63"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> jps</span></code></pre></div>
<p>should give you an output similar to this (PIDs will be
different):</p>
<pre class="text"><code>21922 Jps
21603 NameNode
21787 SecondaryNameNode</code></pre>
<p>For the worker nodes (when you ssh into them and run jps):</p>
<div class="sourceCode" id="cb65"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm1:~$</span> jps</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-arm2:~$</span> jps</span></code></pre></div>
<p>should give you an output similar to this (PIDs will be
different):</p>
<pre class="text"><code>19728 DataNode
19819 Jps</code></pre>
<p>If you don’t see a similar output, check your config files
(especially the HDFS config files.) If you’d like to stop HDFS, you can
use:</p>
<div class="sourceCode" id="cb67"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> stop-dfs.sh</span></code></pre></div>
<h4 id="monitor-hdfs">Monitor HDFS</h4>
<p>You can monitor HDFS by using the command:</p>
<div class="sourceCode" id="cb68"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> hdfs dfsadmin <span class="at">-report</span></span></code></pre></div>
<p>Or you can use the web GUI by entering <a
href="http://masterpublic:9870" class="uri">http://masterpublic:9870</a>
into your browser’s address bar.</p>
<p><a href="https://imgur.com/sIKHNh3"
class="uri">https://imgur.com/sIKHNh3</a></p>
<h3 id="start-yarn">Start YARN</h3>
<p>You can start the YARN framework with the following command (Run on
the master-node):</p>
<div class="sourceCode" id="cb69"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> start-yarn.sh</span></code></pre></div>
<p>You can stop yarn with:</p>
<div class="sourceCode" id="cb70"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> stop-yarn.sh</span></code></pre></div>
<h4 id="monitor-yarn">Monitor YARN</h4>
<p>You can print a report of the running nodes using the command:</p>
<div class="sourceCode" id="cb71"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> yarn node <span class="at">-list</span></span></code></pre></div>
<p>You can also monitor YARN using the web GUI by entering <a
href="http://masterpublic:8088" class="uri">http://masterpublic:8088</a>
into your browser’s address bar.</p>
<p><a href="https://imgur.com/suZgDww"
class="uri">https://imgur.com/suZgDww</a></p>
<h3 id="finish">Finish</h3>
<p>If the HDFS web GUI shows 2 live nodes and the Yarn Web GUI shows 2
active nodes, Hadoop is fully set up! Congrats! If not, check all your
configs and your Oracle port settings. Also check your IP Tables
settings on each of your nodes. The following command</p>
<div class="sourceCode" id="cb72"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="ex">hadoop@node-master:~$</span> sudo iptables <span class="at">-L</span></span></code></pre></div>
<p>should give you the following output:</p>
<pre class="text"><code>Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination

Chain InstanceServices (0 references)
target     prot opt source               destination</code></pre>
<p>If it doesn’t, you need to modify your iptables settings.</p>
            </div>
    </div>
  </div>
  <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>

</body>
</html>
